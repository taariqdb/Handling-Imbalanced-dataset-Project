{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handling Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Handling Imbalance Dataset*"
      ],
      "metadata": {
        "id": "sCKzcBoR1fme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This mini project consist of undersampling , oversampling and smote minority for handling imbalance datasets"
      ],
      "metadata": {
        "id": "_qUJKft-iFzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g4eP_LA127A",
        "outputId": "290199a8-5d87-4692-e530-189dfa7b0e7d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/MyDrive/; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pIK9QkUp2BCW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/MyDrive/MyDrive/Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "B5BwPg7G2bdt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv('/content/MyDrive/MyDrive/Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "V3M0nHmVF-vB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XiJ5Kl12hkM",
        "outputId": "d383eb03-fe2d-45a0-fc78-23a31b132424"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['RowNumber','CustomerId','Surname'],axis=1)"
      ],
      "metadata": {
        "id": "W003Zr0g2j3W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data1.drop(['RowNumber','CustomerId','Surname'],axis=1)"
      ],
      "metadata": {
        "id": "bW7cE9usGNaU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgnCbCuN2uxn",
        "outputId": "ecad89e4-bdd4-4588-c1ca-7c6d9022b90a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
              "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
              "       'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_unique(data):\n",
        "  for column in data:\n",
        "    if data[column].dtypes == 'object':\n",
        "      print(f'{column}:{data[column].unique()}')"
      ],
      "metadata": {
        "id": "yio82tr_2xM2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_unique(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3TEjUqc3POA",
        "outputId": "f79cd0b1-0105-4e23-cc05-3c81294f10ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geography:['France' 'Spain' 'Germany']\n",
            "Gender:['Female' 'Male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_unique(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK5nisCnGUNV",
        "outputId": "405ff6d2-98c2-4c89-83c6-0acbc3abab8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geography:['France' 'Spain' 'Germany']\n",
            "Gender:['Female' 'Male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Gender'].replace({'Female':0,'Male':1},inplace=True)"
      ],
      "metadata": {
        "id": "nA_-WyW-3fCo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1['Gender'].replace({'Female':0,'Male':1},inplace=True)"
      ],
      "metadata": {
        "id": "Ovk8TVAjGWoW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data:\n",
        "  print(f'{column} : {data[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiGS18xw5AAB",
        "outputId": "167e49ed-8328-408f-e0d1-9f5afa5bc6b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
            " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
            " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
            " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
            " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
            " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
            " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
            " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
            " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
            " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
            " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
            " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
            " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
            " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
            " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
            " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
            " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
            " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
            " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
            " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
            " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
            " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
            " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
            " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
            " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
            " 433 442 424 448 441 367 412 382 373 419]\n",
            "Geography : ['France' 'Spain' 'Germany']\n",
            "Gender : [0 1]\n",
            "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
            " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
            " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
            "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
            "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
            "NumOfProducts : [1 3 2 4]\n",
            "HasCrCard : [1 0]\n",
            "IsActiveMember : [1 0]\n",
            "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
            "Exited : [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data1:\n",
        "  print(f'{column} : {data1[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73osY-CdGe5i",
        "outputId": "cb088e5c-c8e9-43e5-b177-a8eb2d3955c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
            " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
            " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
            " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
            " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
            " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
            " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
            " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
            " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
            " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
            " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
            " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
            " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
            " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
            " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
            " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
            " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
            " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
            " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
            " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
            " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
            " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
            " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
            " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
            " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
            " 433 442 424 448 441 367 412 382 373 419]\n",
            "Geography : ['France' 'Spain' 'Germany']\n",
            "Gender : [0 1]\n",
            "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
            " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
            " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
            "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
            "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
            "NumOfProducts : [1 3 2 4]\n",
            "HasCrCard : [1 0]\n",
            "IsActiveMember : [1 0]\n",
            "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
            "Exited : [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data=data, columns=['Geography'])"
      ],
      "metadata": {
        "id": "7nlsFdwv5KOk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.get_dummies(data=data1, columns=['Geography'])"
      ],
      "metadata": {
        "id": "NfwbiSZyGcHy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data:\n",
        "  print(f'{column}:{data[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m-zulmp5VC0",
        "outputId": "6b32092f-d762-4a30-874c-faeba52ef5ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore:[619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
            " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
            " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
            " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
            " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
            " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
            " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
            " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
            " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
            " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
            " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
            " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
            " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
            " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
            " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
            " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
            " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
            " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
            " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
            " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
            " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
            " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
            " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
            " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
            " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
            " 433 442 424 448 441 367 412 382 373 419]\n",
            "Gender:[0 1]\n",
            "Age:[42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
            " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
            " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
            "Tenure:[ 2  1  8  7  4  6  3 10  5  9  0]\n",
            "Balance:[     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
            "NumOfProducts:[1 3 2 4]\n",
            "HasCrCard:[1 0]\n",
            "IsActiveMember:[1 0]\n",
            "EstimatedSalary:[101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
            "Exited:[1 0]\n",
            "Geography_France:[1 0]\n",
            "Geography_Germany:[0 1]\n",
            "Geography_Spain:[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data1:\n",
        "  print(f'{column} : {data1[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFgrpz5HGuNg",
        "outputId": "155a7ced-d1b4-4632-8ec1-d2a9d7354596"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
            " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
            " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
            " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
            " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
            " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
            " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
            " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
            " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
            " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
            " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
            " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
            " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
            " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
            " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
            " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
            " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
            " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
            " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
            " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
            " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
            " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
            " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
            " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
            " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
            " 433 442 424 448 441 367 412 382 373 419]\n",
            "Gender : [0 1]\n",
            "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
            " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
            " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
            "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
            "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
            "NumOfProducts : [1 3 2 4]\n",
            "HasCrCard : [1 0]\n",
            "IsActiveMember : [1 0]\n",
            "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
            "Exited : [1 0]\n",
            "Geography_France : [1 0]\n",
            "Geography_Germany : [0 1]\n",
            "Geography_Spain : [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Exited'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDZeJNIE599H",
        "outputId": "6ef7fe44-474a-494d-83c0-10f6dc0e5fe4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_scale = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data[cols_to_scale] = scaler.fit_transform(data[cols_to_scale])"
      ],
      "metadata": {
        "id": "XOkKAmvNfjqP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_scale = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data1[cols_to_scale] = scaler.fit_transform(data1[cols_to_scale])"
      ],
      "metadata": {
        "id": "eBwK_itwf_QW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data:\n",
        "  print(f'{column}:{data[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuyqM2EsgMfk",
        "outputId": "1e098c60-edd8-4a55-d8ee-9f8434f1f5b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore:[0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
            " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
            " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
            " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
            " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
            " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
            " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
            " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
            " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
            " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
            " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
            " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
            " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
            " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
            " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
            " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
            " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
            " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
            " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
            " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
            " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
            " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
            " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
            " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
            " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
            " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
            " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
            " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
            " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
            " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
            " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
            " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
            " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
            " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
            " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
            " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
            " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
            " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
            " 0.124 0.064 0.046 0.138]\n",
            "Gender:[0 1]\n",
            "Age:[0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
            " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
            " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
            " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
            " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
            " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
            " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
            " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
            " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
            " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
            " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
            " 0.81081081 0.85135135 1.         0.87837838]\n",
            "Tenure:[0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
            "Balance:[0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
            "NumOfProducts:[0.         0.66666667 0.33333333 1.        ]\n",
            "HasCrCard:[1 0]\n",
            "IsActiveMember:[1 0]\n",
            "EstimatedSalary:[0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
            "Exited:[1 0]\n",
            "Geography_France:[1 0]\n",
            "Geography_Germany:[0 1]\n",
            "Geography_Spain:[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data1:\n",
        "  print(f'{column}:{data1[column].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEAf5f5dgQOW",
        "outputId": "e4af8464-a781-4912-d0af-14cab6a8e346"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore:[0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
            " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
            " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
            " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
            " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
            " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
            " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
            " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
            " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
            " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
            " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
            " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
            " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
            " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
            " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
            " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
            " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
            " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
            " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
            " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
            " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
            " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
            " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
            " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
            " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
            " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
            " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
            " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
            " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
            " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
            " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
            " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
            " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
            " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
            " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
            " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
            " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
            " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
            " 0.124 0.064 0.046 0.138]\n",
            "Gender:[0 1]\n",
            "Age:[0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
            " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
            " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
            " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
            " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
            " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
            " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
            " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
            " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
            " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
            " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
            " 0.81081081 0.85135135 1.         0.87837838]\n",
            "Tenure:[0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
            "Balance:[0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
            "NumOfProducts:[0.         0.66666667 0.33333333 1.        ]\n",
            "HasCrCard:[1 0]\n",
            "IsActiveMember:[1 0]\n",
            "EstimatedSalary:[0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
            "Exited:[1 0]\n",
            "Geography_France:[1 0]\n",
            "Geography_Germany:[0 1]\n",
            "Geography_Spain:[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UnderSampling"
      ],
      "metadata": {
        "id": "v5oYIRI582ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1 = data.Exited.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "data_class_0 = data1[data1['Exited'] == 0]\n",
        "data_class_1 = data1[data1['Exited'] == 1]"
      ],
      "metadata": {
        "id": "V2SxCFK-6g7S"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_class_0.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ99MCxB8Jo_",
        "outputId": "b182fbdb-f2d6-4247-f7f8-c00ddf0ac831"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7963 entries, 1 to 9999\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   CreditScore        7963 non-null   float64\n",
            " 1   Gender             7963 non-null   int64  \n",
            " 2   Age                7963 non-null   float64\n",
            " 3   Tenure             7963 non-null   float64\n",
            " 4   Balance            7963 non-null   float64\n",
            " 5   NumOfProducts      7963 non-null   float64\n",
            " 6   HasCrCard          7963 non-null   int64  \n",
            " 7   IsActiveMember     7963 non-null   int64  \n",
            " 8   EstimatedSalary    7963 non-null   float64\n",
            " 9   Exited             7963 non-null   int64  \n",
            " 10  Geography_France   7963 non-null   uint8  \n",
            " 11  Geography_Germany  7963 non-null   uint8  \n",
            " 12  Geography_Spain    7963 non-null   uint8  \n",
            "dtypes: float64(6), int64(4), uint8(3)\n",
            "memory usage: 707.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_class_0_under = data_class_0.sample(count_class_1)"
      ],
      "metadata": {
        "id": "4o1TTFF-8K9n"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_class_0_under"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ltQtAkP_8jgM",
        "outputId": "7783ab83-1e73-4126-8832-dabb7ca2863d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
              "9869        0.342       1  0.270270     0.6  0.000000       0.333333   \n",
              "6485        0.580       1  0.108108     0.5  0.360317       0.000000   \n",
              "9403        0.576       0  0.243243     0.6  0.000000       0.000000   \n",
              "7581        0.716       1  0.324324     0.9  0.704279       0.333333   \n",
              "3499        0.534       1  0.756757     1.0  0.000000       0.333333   \n",
              "...           ...     ...       ...     ...       ...            ...   \n",
              "7792        0.480       1  0.297297     0.8  0.000000       0.333333   \n",
              "5631        0.564       1  0.297297     0.5  0.588489       0.000000   \n",
              "8079        0.586       1  0.256757     0.6  0.000000       0.333333   \n",
              "5968        0.352       1  0.135135     0.1  0.446677       0.000000   \n",
              "9701        0.656       1  0.270270     0.3  0.496152       0.000000   \n",
              "\n",
              "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
              "9869          1               0         0.257237       0                 1   \n",
              "6485          1               1         0.016437       0                 0   \n",
              "9403          1               0         0.821258       0                 1   \n",
              "7581          1               1         0.524016       0                 0   \n",
              "3499          1               1         0.269718       0                 1   \n",
              "...         ...             ...              ...     ...               ...   \n",
              "7792          1               0         0.314637       0                 1   \n",
              "5631          1               1         0.998412       0                 1   \n",
              "8079          0               0         0.712284       0                 1   \n",
              "5968          0               1         0.631412       0                 1   \n",
              "9701          1               0         0.631269       0                 0   \n",
              "\n",
              "      Geography_Germany  Geography_Spain  \n",
              "9869                  0                0  \n",
              "6485                  1                0  \n",
              "9403                  0                0  \n",
              "7581                  1                0  \n",
              "3499                  0                0  \n",
              "...                 ...              ...  \n",
              "7792                  0                0  \n",
              "5631                  0                0  \n",
              "8079                  0                0  \n",
              "5968                  0                0  \n",
              "9701                  0                1  \n",
              "\n",
              "[2037 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18d5f9d9-5bca-4897-9a6c-73c754d93ee7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9869</th>\n",
              "      <td>0.342</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.257237</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>0.580</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.360317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016437</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9403</th>\n",
              "      <td>0.576</td>\n",
              "      <td>0</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.821258</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7581</th>\n",
              "      <td>0.716</td>\n",
              "      <td>1</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.704279</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.524016</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>0.534</td>\n",
              "      <td>1</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.269718</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7792</th>\n",
              "      <td>0.480</td>\n",
              "      <td>1</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.314637</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5631</th>\n",
              "      <td>0.564</td>\n",
              "      <td>1</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.588489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998412</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8079</th>\n",
              "      <td>0.586</td>\n",
              "      <td>1</td>\n",
              "      <td>0.256757</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.712284</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>0.352</td>\n",
              "      <td>1</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.446677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.631412</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9701</th>\n",
              "      <td>0.656</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.496152</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.631269</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2037 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d5f9d9-5bca-4897-9a6c-73c754d93ee7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18d5f9d9-5bca-4897-9a6c-73c754d93ee7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18d5f9d9-5bca-4897-9a6c-73c754d93ee7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test_under = pd.concat([data_class_0_under, data_class_1], axis=0)"
      ],
      "metadata": {
        "id": "IEDkUaw58nh_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random-Sampling:')\n",
        "print(data_test_under.Exited.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14sflEfHCIhc",
        "outputId": "5d3b4be6-1f52-428c-9ac3-5b1709b887ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random-Sampling:\n",
            "0    2037\n",
            "1    2037\n",
            "Name: Exited, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_test_under.drop('Exited',axis=1)"
      ],
      "metadata": {
        "id": "ThqYxePcCW6x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data_test_under['Exited']"
      ],
      "metadata": {
        "id": "Ruu0YiZ-JG6I"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=5, stratify=y)"
      ],
      "metadata": {
        "id": "hlvEdu38JWaC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfEDvtBIJpNd",
        "outputId": "346362a3-9027-4ec7-eb43-7edac8a9e534"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1630\n",
              "1    1629\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R79SAv71JwbD",
        "outputId": "b8127e9c-0e23-4dc4-83e9-c8abffd5b191"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    408\n",
              "0    407\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFajuLXqLD6A",
        "outputId": "6b77ef9f-1d4d-4369-c293-3c88296b5c27"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3259, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ERDZtz5xJy__"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(X_train,y_train,X_test,y_test,loss,weights):\n",
        "  model = keras.Sequential([\n",
        "                            keras.layers.Dense(100,input_shape=(12,),activation='relu'),\n",
        "                            keras.layers.Dense(50,activation='relu'),\n",
        "                            keras.layers.Dense(1,activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  if weights == -1:\n",
        "    model.fit(X_train, y_train, epochs=100)\n",
        "  \n",
        "  else:\n",
        "    model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "\n",
        "  print(model.evaluate(X_test,y_test))\n",
        "  \n",
        "  y_preds = model.predict(X_test)\n",
        "  y_preds = np.round(y_preds)\n",
        "\n",
        "  print(print(\"Classification Report: \\n\", classification_report(y_test, y_preds)))\n",
        "\n",
        "  cm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.heatmap(cm,annot=True,fmt='d')\n",
        "\n",
        "  return y_preds"
      ],
      "metadata": {
        "id": "hmIKwrWdKFEm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d8jMRlw_Lowu",
        "outputId": "ac30f785-3aad-4e36-f70a-51827f973f69"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 1s 2ms/step - loss: 0.6619 - accuracy: 0.6011\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6649\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6950\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7088\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7266\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7318\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7462\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7607\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7604\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7723\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7683\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7702\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7714\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7742\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7775\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7757\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7782\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7831\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7852\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7828\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7843\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7828\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7895\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7874\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7898\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7907\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7956\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7809\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7904\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7880\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7864\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7871\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7920\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7978\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7898\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7947\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8024\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7996\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7996\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8018\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8021\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7987\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8048\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8039\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7987\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8033\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8045\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8024\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8101\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8048\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8088\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8064\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8098\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8098\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8064\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8128\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8076\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8144\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8073\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8165\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8088\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8110\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8165\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8150\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8125\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8187\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8134\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8174\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8159\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8196\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8098\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8180\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8205\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8199\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8248\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8245\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8260\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8285\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8223\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8297\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8239\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8211\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8279\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8223\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8199\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8312\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8251\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8319\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8269\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8288\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8245\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8349\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8233\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8346\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8285\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8331\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8322\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.3601 - accuracy: 0.8380\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8352\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7485\n",
            "[0.5605825781822205, 0.7484662532806396]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.74      0.75       407\n",
            "           1       0.75      0.75      0.75       408\n",
            "\n",
            "    accuracy                           0.75       815\n",
            "   macro avg       0.75      0.75      0.75       815\n",
            "weighted avg       0.75      0.75      0.75       815\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling"
      ],
      "metadata": {
        "id": "H3d6xqTRNOrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_class_1_over = data_class_1.sample(count_class_0, replace=True)\n",
        "data_over = pd.concat([data_class_0, data_class_1_over], axis=0)"
      ],
      "metadata": {
        "id": "yFUyY_FPNJ-x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_over.Exited.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCEbic_gPaRX",
        "outputId": "0c8c5ce9-c533-41c1-cf57-69d95ba7d298"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    7963\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Ov = data_over.drop('Exited',axis=1)\n",
        "y_Ov = data_over['Exited']"
      ],
      "metadata": {
        "id": "LmdKERorPfWJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Ov.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pe6FCW0Tgym",
        "outputId": "68ba1bc4-1157-4aec-ea0b-62e5cdc9698f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
              "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_France',\n",
              "       'Geography_Germany', 'Geography_Spain'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Ov.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl3CF-xXTQlu",
        "outputId": "2ff9dc2a-7b86-4aaf-cada-b62038ac2c66"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15926, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_o,x_test_o,y_train_o,y_test_o = train_test_split(X_Ov,y_Ov, test_size=0.2, random_state=15, stratify=y_Ov)"
      ],
      "metadata": {
        "id": "2Uivb_DLPu7A"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_o.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhUk8CH5TLYI",
        "outputId": "e1abd92d-d65c-4539-c897-2c44bec7420e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    6370\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANN(x_train_o,y_train_o,x_test_o,y_test_o,'binary_crossentropy',-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPpMMGhXT36B",
        "outputId": "8c5e1977-f4a4-46f5-e81d-1c908c6b8de2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 2s 3ms/step - loss: 0.6006 - accuracy: 0.6805\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7370\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7596\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7684\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7695\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7710\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7754\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.7800\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7792\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.7840\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.7868\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.7863\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.7886\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.7888\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.7947\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.7947\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.7972\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4266 - accuracy: 0.7972\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.7983\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.7947\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.7977\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4173 - accuracy: 0.8010\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8023\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4136 - accuracy: 0.8036\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8071\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8049\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8065\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8068\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8097\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8097\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8137\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8155\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3959 - accuracy: 0.8151\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8177\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3942 - accuracy: 0.8158\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8169\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8188\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8230\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3846 - accuracy: 0.8205\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8241\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8228\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8265\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8297\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8301\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8297\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8324\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8301\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3669 - accuracy: 0.8352\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8341\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8351\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8359\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3581 - accuracy: 0.8364\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.8352\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8411\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8428\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8406\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8419\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8427\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8437\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8442\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8439\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8456\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8469\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8486\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8498\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8473\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8497\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8503\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8496\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8487\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8541\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8516\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8553\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8595\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8553\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8553\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8581\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8597\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3154 - accuracy: 0.8614\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3146 - accuracy: 0.8632\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3119 - accuracy: 0.8604\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8642\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.3105 - accuracy: 0.8652\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.8626\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3066 - accuracy: 0.8638\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8672\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8678\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8668\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8641\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8655\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8701\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.8651\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8733\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2943 - accuracy: 0.8722\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8704\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8717\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8730\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8706\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.8739\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.8732\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8484\n",
            "[0.359196275472641, 0.8483992218971252]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85      1593\n",
            "           1       0.83      0.87      0.85      1593\n",
            "\n",
            "    accuracy                           0.85      3186\n",
            "   macro avg       0.85      0.85      0.85      3186\n",
            "weighted avg       0.85      0.85      0.85      3186\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE"
      ],
      "metadata": {
        "id": "JoJmY7s_dVKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Exited',axis='columns')\n",
        "y = data['Exited']"
      ],
      "metadata": {
        "id": "JOzKbrbiUlvK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm, y_sm = smote.fit_resample(X, y)\n",
        "\n",
        "y_sm.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SB_DVNYdcus",
        "outputId": "40d485aa-6cb7-46b8-8ed4-c0c4d50d3ca2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    7963\n",
              "0    7963\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
      ],
      "metadata": {
        "id": "oPuccxV8di15"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in training Data\n",
        "y_train_sm.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmtNzT0ldxsb",
        "outputId": "7e1832ea-3a76-4c20-e660-39c268a98444"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    6370\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANN(X_train_sm, y_train_sm, X_test_sm, y_test_sm, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZEbSTRUEd3Qb",
        "outputId": "bbbdefb9-7e86-475f-a0f3-86bc97b2ec12"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 3s 4ms/step - loss: 0.6041 - accuracy: 0.6698\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.5286 - accuracy: 0.7370\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4885 - accuracy: 0.7604\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4696 - accuracy: 0.7717\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4606 - accuracy: 0.7789\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.7823\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.7864\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.7896\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4355 - accuracy: 0.7950\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.7953\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8004\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.8007\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8033\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8053\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8072\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8100\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8055\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4078 - accuracy: 0.8102\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8114\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8141\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8150\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8158\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8159\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3926 - accuracy: 0.8199\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3884 - accuracy: 0.8211\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3884 - accuracy: 0.8195\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3849 - accuracy: 0.8242\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3814 - accuracy: 0.8229\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3785 - accuracy: 0.8279\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3738 - accuracy: 0.8276\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8273\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3684 - accuracy: 0.8321\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3660 - accuracy: 0.8342\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8341\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8374\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3572 - accuracy: 0.8394\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8405\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8417\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8442\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8425\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8470\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8469\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8479\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8468\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8492\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8476\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8480\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8522\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8522\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8562\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8554\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8564\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8564\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8536\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3219 - accuracy: 0.8565\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8582\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8578\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8599\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8613\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3154 - accuracy: 0.8605\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8600\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8615\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8652\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8684\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8655\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3050 - accuracy: 0.8686\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8674\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8670\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8684\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8659\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8673\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8672\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8716\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3000 - accuracy: 0.8699\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8701\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8719\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8714\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8704\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8730\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.8722\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.8744\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2924 - accuracy: 0.8748\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2863 - accuracy: 0.8766\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2875 - accuracy: 0.8763\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.8777\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.8763\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8763\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.8804\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8797\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8823\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.8788\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2801 - accuracy: 0.8785\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8777\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.8797\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8809\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8812\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8836\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.8843\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8850\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8854\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8531\n",
            "[0.3499314785003662, 0.8531073331832886]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.79      0.84      1593\n",
            "           1       0.81      0.92      0.86      1593\n",
            "\n",
            "    accuracy                           0.85      3186\n",
            "   macro avg       0.86      0.85      0.85      3186\n",
            "weighted avg       0.86      0.85      0.85      3186\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h8Saxyemd91h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}